---
title: "Incentives and Trust"
date: 2019-01-24T23:29:33+02:00
draft: false
---

Incentives seem very well understood. We have a whole bunch of natural sounding ideas, such as 

* If you reward a person for a specific behaviour, you'll encourage more of that behaviour.
* If you punish someone for a specific behaviour, you'll encourage less of that behaviour.
* If you need someone to do something that they don't want to do, you need to monitor them to make sure that they actually do it.
* Once you have monitored someone enough and they habitually do what they are meant to, then you have built mutual trust and you can stop the monitoring, or start monitoring randomly instead of constantly.

A lot of these kinds of ideas come from the BF Skinner, who was and is well respected for the very precise and scientific methods he used to study behaviour. The idea of applying something as clean-cut as science to something as messy as human behaviour wasn't always obvious. And people are starting to question it again. To misquote someone, "Skinner did most of his experiments on rats and drew most of his conclusions about humans". 

Similarly, Taylorism or "Scientific Management" was invented in the early 1900s . The idea of treating people like any other resource and optimising labour processes seems fairly natural now to anyone who has worked in an office with HR policies and commission structures, but this wasn't always a common opinion. And it too is slowly being questioned. 

Incentives are hard. It's easy to fall into situations of [The Cobra Effect](https://en.wikipedia.org/wiki/Cobra_effect) when designing them, in which the incentive actually encourages the opposite result of what was intended. Even when incentives work short term to modify other's behaviour, longer term they can [often have a negative result](https://www.amazon.com/Punished-Rewards-Trouble-Incentive-Praise/dp/0618001816). 

Monitoring people can similarly [lead to an increase in undesired behaviour](https://hbr.org/2018/04/why-monitoring-your-employees-behavior-can-backfire), as people will be motivated to beat the system, and they won't feel bad about cheating because they're not breaking your trust (if you're monitoring, you're indicating that an absence of trust).

All of these incentive and monitoring based strategies only *seem* intuitive to us because we've been taught that they are "science". But they are inventions, not discoveries, and the opposite strategies can be used as or more effectively to reach the same goals.

Not rewarding people for behaviour can help them focus on intrinsic rather than extrinsic motivation. Avoiding punishing people for bad behaviour means that you don't have to deal with resent. Not monitoring people indicates that you trust them, and people are usually very hesitant to break trust when it is offered. 

Talk to individual people instead of resources. Look for shared goals to work towards together instead of identifying your goals and incentivising others to help you get there. Be suspicious of anyone who thinks that people should be treated as resources.