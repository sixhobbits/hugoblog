<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Gareth Dwyer</title>
    <link>sixhobbits.github.io/hugoblog/</link>
    <description>Recent content on Gareth Dwyer</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 13 Jan 2019 20:00:00 +0200</lastBuildDate>
    
	<atom:link href="sixhobbits.github.io/hugoblog/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Writing 500 words per day</title>
      <link>sixhobbits.github.io/hugoblog/posts/2019-01-13-publish-daily-habit/</link>
      <pubDate>Sun, 13 Jan 2019 20:00:00 +0200</pubDate>
      
      <guid>sixhobbits.github.io/hugoblog/posts/2019-01-13-publish-daily-habit/</guid>
      <description>I didn&amp;rsquo;t make any resolutions for 2019, but I would like this year to be one of building constructive habits. I skimmed some concepts in 2018 around the power of habit, and spent some time with ideas like &amp;lsquo;Do we spend too much time focusing on things topics like Inspiration when most of what we achieve is actually driven by self discipline and habit&amp;rsquo;.
I fell in and out of several good and bad habits during 2018, including a reading habit where I read a bunch of books, a note-taking habit where I took copious notes about each of these books, and a writing habit, where I worked each morning for an hour on writing technical tutorials, emails, or other ideas.</description>
    </item>
    
    <item>
      <title>Beginner web scraping with Python and Repl.it</title>
      <link>sixhobbits.github.io/hugoblog/posts/my-first-post/</link>
      <pubDate>Mon, 31 Dec 2018 14:51:29 +0200</pubDate>
      
      <guid>sixhobbits.github.io/hugoblog/posts/my-first-post/</guid>
      <description>In this guide, we&amp;rsquo;ll walk through how to automatically grab data from web sites. Most websites are created with a human audience in mind - you use a search engine or type a URL into your web browser, and see information displayed on the page. Sometimes, we want to automatically extract and process this data, and this is where web scraping can save us from boring repetitive labour. We can create a custom computer program to visit web sites, extract specific data and process this data in a specific way.</description>
    </item>
    
  </channel>
</rss>